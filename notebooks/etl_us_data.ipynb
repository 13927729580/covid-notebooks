{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# etl_us_data.ipynb\n",
    "\n",
    "Acquire a copy of the latest COVID-19 time series data and write that\n",
    "data out into local CSV files in a format amenable to analysis with \n",
    "Pandas dataframes.\n",
    "\n",
    "Input data sources:\n",
    "* [2019 Novel Coronavirus COVID-19 (2019-nCoV) Data Repository by Johns Hopkins CSSE](https://github.com/CSSEGISandData/COVID-19).\n",
    "\n",
    "Output files produced:\n",
    "* `data/us_counties.csv`: County-level time series data for the United States\n",
    "* `data/us_counties_meta.json`: Column type metadata for reading `data/us_counties.csv` with `pd.read_csv()`\n",
    "\n",
    "To read these files back in, use `pd.read_csv()`:\n",
    "```python\n",
    "with open(\"data/us_counties_meta.json\") as f:\n",
    "    cases_meta = json.load(f)\n",
    "cases_meta[\"Date\"] = \"object\"  # Workaround for pd.read_csv() not supporting parsing datetime64\n",
    "cases_raw = pd.read_csv(\"../data/us_counties.csv\", dtype=cases_meta, parse_dates=[\"Date\"])\n",
    "cases = cases_raw.set_index([\"FIPS\", \"Date\"], verify_integrity=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization boilerplate\n",
    "\n",
    "# Ensure a consistent Python environment.\n",
    "import sys\n",
    "sys.path.append(\"..\")  # Local libraries are in the directory above \"notebooks\"\n",
    "import env\n",
    "env.maybe_install_libs()\n",
    "\n",
    "# Import Python packages that this notebook uses.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from datetime import datetime, date\n",
    "\n",
    "# URLs for downloading the time series data directly from Github\n",
    "_JH_BASE_URL = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/\" + \\\n",
    "               \"csse_covid_19_data/csse_covid_19_time_series/\"\n",
    "_JH_CONFIRMED_URL = _JH_BASE_URL + \"time_series_covid19_confirmed_US.csv\"\n",
    "_JH_DEATHS_URL = _JH_BASE_URL + \"time_series_covid19_deaths_US.csv\"\n",
    "\n",
    "# Currently there are no data on recovered patients for the US.\n",
    "# _JH_RECOVERED_URL = _JH_BASE_URL + \"time_series_covid19_recovered_US.csv\"\n",
    "\n",
    "\n",
    "# First date present in the data set, and the format of these dates. \n",
    "# Hopefully this won't change as new data are added.\n",
    "# NOTE: One file uses \"01/22/20\" and the other uses \"1/22/20\"\n",
    "# so you need to filter with endswith() to find matches.\n",
    "_FIRST_DATE_SUFFIX = \"1/22/20\"\n",
    "_DATE_FORMAT = \"%m/%d/%y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>4/18/20</th>\n",
       "      <th>4/19/20</th>\n",
       "      <th>4/20/20</th>\n",
       "      <th>4/21/20</th>\n",
       "      <th>4/22/20</th>\n",
       "      <th>4/23/20</th>\n",
       "      <th>4/24/20</th>\n",
       "      <th>4/25/20</th>\n",
       "      <th>4/26/20</th>\n",
       "      <th>4/27/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>ASM</td>\n",
       "      <td>16</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>US</td>\n",
       "      <td>-14.271000</td>\n",
       "      <td>-170.132000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316.0</td>\n",
       "      <td>GU</td>\n",
       "      <td>GUM</td>\n",
       "      <td>316</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Guam</td>\n",
       "      <td>US</td>\n",
       "      <td>13.444300</td>\n",
       "      <td>144.793700</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>139</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>580.0</td>\n",
       "      <td>MP</td>\n",
       "      <td>MNP</td>\n",
       "      <td>580</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Mariana Islands</td>\n",
       "      <td>US</td>\n",
       "      <td>15.097900</td>\n",
       "      <td>145.673900</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630.0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PRI</td>\n",
       "      <td>630</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>18.220800</td>\n",
       "      <td>-66.590100</td>\n",
       "      <td>...</td>\n",
       "      <td>1118</td>\n",
       "      <td>1213</td>\n",
       "      <td>1252</td>\n",
       "      <td>1298</td>\n",
       "      <td>1252</td>\n",
       "      <td>1416</td>\n",
       "      <td>1276</td>\n",
       "      <td>1307</td>\n",
       "      <td>1371</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850.0</td>\n",
       "      <td>VI</td>\n",
       "      <td>VIR</td>\n",
       "      <td>850</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin Islands</td>\n",
       "      <td>US</td>\n",
       "      <td>18.335800</td>\n",
       "      <td>-64.896300</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>84070017.0</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southeast Utah</td>\n",
       "      <td>Utah</td>\n",
       "      <td>US</td>\n",
       "      <td>38.996171</td>\n",
       "      <td>-110.701396</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>84070018.0</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest Utah</td>\n",
       "      <td>Utah</td>\n",
       "      <td>US</td>\n",
       "      <td>37.854472</td>\n",
       "      <td>-111.441876</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>76</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "      <td>87</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>84070019.0</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TriCounty</td>\n",
       "      <td>Utah</td>\n",
       "      <td>US</td>\n",
       "      <td>40.124915</td>\n",
       "      <td>-109.517442</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>84070020.0</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Weber-Morgan</td>\n",
       "      <td>Utah</td>\n",
       "      <td>US</td>\n",
       "      <td>41.271160</td>\n",
       "      <td>-111.914512</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>124</td>\n",
       "      <td>126</td>\n",
       "      <td>130</td>\n",
       "      <td>136</td>\n",
       "      <td>140</td>\n",
       "      <td>143</td>\n",
       "      <td>145</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>90049.0</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>Utah</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3262 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             UID iso2 iso3  code3     FIPS          Admin2  \\\n",
       "0           16.0   AS  ASM     16     60.0             NaN   \n",
       "1          316.0   GU  GUM    316     66.0             NaN   \n",
       "2          580.0   MP  MNP    580     69.0             NaN   \n",
       "3          630.0   PR  PRI    630     72.0             NaN   \n",
       "4          850.0   VI  VIR    850     78.0             NaN   \n",
       "...          ...  ...  ...    ...      ...             ...   \n",
       "3257  84070017.0   US  USA    840      NaN  Southeast Utah   \n",
       "3258  84070018.0   US  USA    840      NaN  Southwest Utah   \n",
       "3259  84070019.0   US  USA    840      NaN       TriCounty   \n",
       "3260  84070020.0   US  USA    840      NaN    Weber-Morgan   \n",
       "3261         NaN   US  USA    840  90049.0       Southwest   \n",
       "\n",
       "                Province_State Country_Region        Lat       Long_  ...  \\\n",
       "0               American Samoa             US -14.271000 -170.132000  ...   \n",
       "1                         Guam             US  13.444300  144.793700  ...   \n",
       "2     Northern Mariana Islands             US  15.097900  145.673900  ...   \n",
       "3                  Puerto Rico             US  18.220800  -66.590100  ...   \n",
       "4               Virgin Islands             US  18.335800  -64.896300  ...   \n",
       "...                        ...            ...        ...         ...  ...   \n",
       "3257                      Utah             US  38.996171 -110.701396  ...   \n",
       "3258                      Utah             US  37.854472 -111.441876  ...   \n",
       "3259                      Utah             US  40.124915 -109.517442  ...   \n",
       "3260                      Utah             US  41.271160 -111.914512  ...   \n",
       "3261                      Utah             US        NaN         NaN  ...   \n",
       "\n",
       "     4/18/20  4/19/20  4/20/20  4/21/20  4/22/20  4/23/20  4/24/20  4/25/20  \\\n",
       "0          0        0        0        0        0        0        0        0   \n",
       "1        136      136      136      136      136      139      141      141   \n",
       "2         14       14       14       14       14       14       14       14   \n",
       "3       1118     1213     1252     1298     1252     1416     1276     1307   \n",
       "4         53       53       53       53       54       54       54       55   \n",
       "...      ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "3257       0        6        7        7        7        7        8       11   \n",
       "3258       0       66       70       70       70       76       81       83   \n",
       "3259       0       10       10       10        9        9        9        9   \n",
       "3260       0      119      124      126      130      136      140      143   \n",
       "3261       0        0        0        0        0        0        0        0   \n",
       "\n",
       "      4/26/20  4/27/20  \n",
       "0           0        0  \n",
       "1         141      141  \n",
       "2          14       14  \n",
       "3        1371     1389  \n",
       "4          57       57  \n",
       "...       ...      ...  \n",
       "3257       12       13  \n",
       "3258       87       89  \n",
       "3259       10       11  \n",
       "3260      145      148  \n",
       "3261        0        0  \n",
       "\n",
       "[3262 rows x 108 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the raw data from Github\n",
    "raw_confirmed = pd.read_csv(_JH_CONFIRMED_URL)\n",
    "raw_deaths = pd.read_csv(_JH_DEATHS_URL)\n",
    "\n",
    "# No \"recovered\" time series at the moment. Generate an empty\n",
    "# time series the schema from the deaths\n",
    "raw_recovered = raw_deaths.copy(deep=True)\n",
    "for i in range(len(raw_recovered.columns)):\n",
    "    if str(raw_recovered.columns[i]).endswith(_FIRST_DATE_SUFFIX):\n",
    "        ts_start_index = i\n",
    "        break\n",
    "for c in raw_recovered.columns[ts_start_index:]:\n",
    "    raw_recovered[c] = 0\n",
    "\n",
    "raw_confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/romeokienzler/opt/anaconda3/envs/tf2.0/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>iso2</th>\n",
       "      <th>iso3</th>\n",
       "      <th>code3</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Admin2</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long_</th>\n",
       "      <th>...</th>\n",
       "      <th>4/18/20</th>\n",
       "      <th>4/19/20</th>\n",
       "      <th>4/20/20</th>\n",
       "      <th>4/21/20</th>\n",
       "      <th>4/22/20</th>\n",
       "      <th>4/23/20</th>\n",
       "      <th>4/24/20</th>\n",
       "      <th>4/25/20</th>\n",
       "      <th>4/26/20</th>\n",
       "      <th>4/27/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>ASM</td>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Samoa</td>\n",
       "      <td>US</td>\n",
       "      <td>-14.2710</td>\n",
       "      <td>-170.1320</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316.0</td>\n",
       "      <td>GU</td>\n",
       "      <td>GUM</td>\n",
       "      <td>316</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Guam</td>\n",
       "      <td>US</td>\n",
       "      <td>13.4443</td>\n",
       "      <td>144.7937</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>139</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>580.0</td>\n",
       "      <td>MP</td>\n",
       "      <td>MNP</td>\n",
       "      <td>580</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Northern Mariana Islands</td>\n",
       "      <td>US</td>\n",
       "      <td>15.0979</td>\n",
       "      <td>145.6739</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630.0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PRI</td>\n",
       "      <td>630</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>US</td>\n",
       "      <td>18.2208</td>\n",
       "      <td>-66.5901</td>\n",
       "      <td>...</td>\n",
       "      <td>1118</td>\n",
       "      <td>1213</td>\n",
       "      <td>1252</td>\n",
       "      <td>1298</td>\n",
       "      <td>1252</td>\n",
       "      <td>1416</td>\n",
       "      <td>1276</td>\n",
       "      <td>1307</td>\n",
       "      <td>1371</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850.0</td>\n",
       "      <td>VI</td>\n",
       "      <td>VIR</td>\n",
       "      <td>850</td>\n",
       "      <td>78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin Islands</td>\n",
       "      <td>US</td>\n",
       "      <td>18.3358</td>\n",
       "      <td>-64.8963</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>84090054.0</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>90054</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>US</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>84090055.0</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>90055</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>US</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>84090056.0</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>90056</td>\n",
       "      <td>Unassigned</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>US</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>84099999.0</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>99999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Grand Princess</td>\n",
       "      <td>US</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>840</td>\n",
       "      <td>90049</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>Utah</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3252 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             UID iso2 iso3  code3   FIPS      Admin2  \\\n",
       "0           16.0   AS  ASM     16     60         NaN   \n",
       "1          316.0   GU  GUM    316     66         NaN   \n",
       "2          580.0   MP  MNP    580     69         NaN   \n",
       "3          630.0   PR  PRI    630     72         NaN   \n",
       "4          850.0   VI  VIR    850     78         NaN   \n",
       "...          ...  ...  ...    ...    ...         ...   \n",
       "3249  84090054.0   US  USA    840  90054  Unassigned   \n",
       "3250  84090055.0   US  USA    840  90055  Unassigned   \n",
       "3251  84090056.0   US  USA    840  90056  Unassigned   \n",
       "3252  84099999.0   US  USA    840  99999         NaN   \n",
       "3261         NaN   US  USA    840  90049   Southwest   \n",
       "\n",
       "                Province_State Country_Region      Lat     Long_  ... 4/18/20  \\\n",
       "0               American Samoa             US -14.2710 -170.1320  ...       0   \n",
       "1                         Guam             US  13.4443  144.7937  ...     136   \n",
       "2     Northern Mariana Islands             US  15.0979  145.6739  ...      14   \n",
       "3                  Puerto Rico             US  18.2208  -66.5901  ...    1118   \n",
       "4               Virgin Islands             US  18.3358  -64.8963  ...      53   \n",
       "...                        ...            ...      ...       ...  ...     ...   \n",
       "3249             West Virginia             US   0.0000    0.0000  ...       0   \n",
       "3250                 Wisconsin             US   0.0000    0.0000  ...       0   \n",
       "3251                   Wyoming             US   0.0000    0.0000  ...       0   \n",
       "3252            Grand Princess             US   0.0000    0.0000  ...     103   \n",
       "3261                      Utah             US      NaN       NaN  ...       0   \n",
       "\n",
       "      4/19/20  4/20/20  4/21/20  4/22/20  4/23/20  4/24/20  4/25/20  4/26/20  \\\n",
       "0           0        0        0        0        0        0        0        0   \n",
       "1         136      136      136      136      139      141      141      141   \n",
       "2          14       14       14       14       14       14       14       14   \n",
       "3        1213     1252     1298     1252     1416     1276     1307     1371   \n",
       "4          53       53       53       54       54       54       55       57   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "3249        0        0        0        0        0        0        0        0   \n",
       "3250        0        0        0        0        0        0        0        0   \n",
       "3251        0        0        0        0        0        0        0        0   \n",
       "3252      103      103      103      103      103      103      103      103   \n",
       "3261        0        0        0        0        0        0        0        0   \n",
       "\n",
       "      4/27/20  \n",
       "0           0  \n",
       "1         141  \n",
       "2          14  \n",
       "3        1389  \n",
       "4          57  \n",
       "...       ...  \n",
       "3249        0  \n",
       "3250        0  \n",
       "3251        0  \n",
       "3252      103  \n",
       "3261        0  \n",
       "\n",
       "[3252 rows x 108 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some of the FIPS codes contain NA's. Remove those data points. TODO fred review (romeo)\n",
    "raw_confirmed = raw_confirmed[~raw_confirmed[\"FIPS\"].isna()]\n",
    "raw_deaths = raw_deaths[~raw_deaths[\"FIPS\"].isna()]\n",
    "raw_recovered = raw_recovered[~raw_recovered[\"FIPS\"].isna()]\n",
    "\n",
    "\n",
    "# For some reason, the FIPS codes are encoded as floats. Fix that.\n",
    "for df in [raw_confirmed, raw_deaths, raw_recovered]:\n",
    "    df[\"FIPS\"] = df[\"FIPS\"].astype(\"Int64\")\n",
    "    \n",
    "raw_confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down to just U.S. counties\n",
    "def counties_df(df):\n",
    "    return df[(df[\"FIPS\"] >= 1000)  # Territories have FIPS codes < 1000\n",
    "              & (~df[\"Admin2\"].isna())  # Countries don't have the \"Admin2\" field set\n",
    "              & (df[\"Admin2\"] != \"Unassigned\")  # States have Admin2 set to \"Unassigned\"\n",
    "              & (df[\"FIPS\"] <= 60000)  # Expatriates are coded by state in values > 80k\n",
    "              ].copy()\n",
    "\n",
    "county_confirmed = counties_df(raw_confirmed)\n",
    "county_deaths = counties_df(raw_deaths)\n",
    "county_recovered = counties_df(raw_recovered)\n",
    "\n",
    "county_confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The time series in the raw data are spread across multiple columns.\n",
    "# Rotate them by 90 degrees so that they are spread across rows.\n",
    "\n",
    "def shred_time_series(df: pd.DataFrame, colname: str):\n",
    "    \"\"\"\n",
    "    Turn a time series encoded as a range of columns into a time series\n",
    "    encoded as a range of rows.\n",
    "    \n",
    "    This function hard-codes the column name mapping for Johns Hopkins \n",
    "    data, so it will only work on that data.\n",
    "    \n",
    "    :param df: Dataframe with a time series across the columns of each row,\n",
    "     with an additional outer join indicator column at the very end.\n",
    "    :param colname: Name of the new column where the time series should go\n",
    "    \n",
    "    :returns: A dataframe with one time series element per row.\n",
    "     The returned dataframe will have a column called \"Date\" with the date\n",
    "     of each time series element, and a column with the name `colname` with\n",
    "     the associated value for each date.\n",
    "    \"\"\"\n",
    "    for i in range(len(df.columns)):\n",
    "        if str(df.columns[i]).endswith(_FIRST_DATE_SUFFIX):\n",
    "            ts_start_index = i\n",
    "            break\n",
    "    \n",
    "    # Note the -1 index to strip off the outer join indicator variable\n",
    "    ts_matrix = df[df.columns[ts_start_index:-1]].values\n",
    "    ts_lists = ts_matrix.tolist()\n",
    "\n",
    "    date_list = [datetime.strptime(s, _DATE_FORMAT) for s in df.columns[ts_start_index:-1]]\n",
    "\n",
    "    # Create a new dataframe where the time series is a list\n",
    "    nested_df = df[df.columns[:ts_start_index]].copy()\n",
    "    nested_df[colname] = ts_lists\n",
    "\n",
    "    # Expand out the list and add the dates back.\n",
    "    flat_df = nested_df.explode(colname)\n",
    "    flat_df[\"Date\"] = date_list * len(nested_df.index)\n",
    "    return flat_df\n",
    "\n",
    "shredded_confirmed = shred_time_series(county_confirmed, \"Confirmed\")\n",
    "shredded_deaths = shred_time_series(county_deaths, \"Deaths\")\n",
    "shredded_recovered = shred_time_series(county_recovered, \"Recovered\")\n",
    "shredded_confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the three time series into a single table.\n",
    "\n",
    "# Sort by FIPS code and Date and clean up some columns that don't match\n",
    "# perfectly.\n",
    "sorted_deaths = shredded_deaths.sort_values([\"FIPS\", \"Date\"])\n",
    "sorted_confirmed = shredded_confirmed.sort_values([\"FIPS\", \"Date\"])\n",
    "sorted_recovered = shredded_recovered.sort_values([\"FIPS\", \"Date\"])\n",
    "\n",
    "# The \"confirmed\" time series is missing the \"population\" column that is\n",
    "# present in the \"deaths\" and \"recovered\" time series.\n",
    "# Add it back in.\n",
    "sorted_confirmed[\"Population\"] = sorted_deaths[\"Population\"]\n",
    "\n",
    "# The floating point numbers in the \"Lat\" and \"Long_\" fields also have\n",
    "# some discrepancies due to rounding error. Use the values in the \n",
    "# \"confirmed\" time series as the gold standard.\n",
    "sorted_deaths[\"Lat\"] = sorted_confirmed[\"Lat\"]\n",
    "sorted_deaths[\"Long_\"] = sorted_confirmed[\"Long_\"]\n",
    "sorted_recovered[\"Lat\"] = sorted_confirmed[\"Lat\"]\n",
    "sorted_recovered[\"Long_\"] = sorted_confirmed[\"Long_\"]\n",
    "\n",
    "# Now we can combine the three time series into a single table\n",
    "combined = (\n",
    "    sorted_confirmed\n",
    "    .merge(sorted_deaths, how=\"outer\")\n",
    "    .merge(sorted_recovered, how=\"outer\"))\n",
    "\n",
    "# Check for missing data\n",
    "missing_rows = combined[combined[\"Confirmed\"].isna()]\n",
    "if len(missing_rows.index) > 0:\n",
    "    raise ValueError(f\"Missing 'Confirmed' time series data for the following rows:\\n{missing_rows}\")\n",
    "\n",
    "combined  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The outer joins in the previous cell convert some of the integer\n",
    "# columns to object types. Fix that.\n",
    "\n",
    "# Data types before:\n",
    "combined.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"iso2\"] = combined[\"iso2\"].astype(\"string\")\n",
    "combined[\"iso3\"] = combined[\"iso3\"].astype(\"string\")\n",
    "combined[\"Admin2\"] = combined[\"Admin2\"].astype(\"string\")\n",
    "combined[\"Province_State\"] = combined[\"Province_State\"].astype(\"string\")\n",
    "combined[\"Country_Region\"] = combined[\"Country_Region\"].astype(\"string\")\n",
    "combined[\"Combined_Key\"] = combined[\"Combined_Key\"].astype(\"string\")\n",
    "\n",
    "combined[\"Confirmed\"] = combined[\"Confirmed\"].astype(np.int64)\n",
    "combined[\"Deaths\"] = combined[\"Deaths\"].astype(np.int64)\n",
    "combined[\"Recovered\"] = combined[\"Recovered\"].astype(np.int64)\n",
    "\n",
    "# Data types after:\n",
    "combined.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Massage the column names a bit and drop unnecessary columns\n",
    "to_retain = combined[[\"Date\", \"FIPS\", \"Province_State\", \"Admin2\", \n",
    "                      \"Population\",\n",
    "                      \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "to_write = to_retain.rename(columns={\n",
    "    \"Province_State\": \"State\",\n",
    "    \"Admin2\": \"County\"\n",
    "})\n",
    "to_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data out to a CSV file + a JSON file of type info.\n",
    "to_write.to_csv(\"../data/us_counties.csv\", index=False)\n",
    "col_type_mapping = {\n",
    "    key: str(value) for key, value in to_write.dtypes.iteritems()\n",
    "}\n",
    "with open(\"../data/us_counties_meta.json\", \"w\") as f:\n",
    "    json.dump(col_type_mapping, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh ../data/us_counties*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
